{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1b141602-08ef-41e1-9415-6fe2b745711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import cv2\n",
    "import csv\n",
    "import glob\n",
    "import pytesseract\n",
    "import os\n",
    "import urllib.request\n",
    "import httplib2\n",
    "\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "227a5949-ce11-4c7b-b374-0bc9c50c4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_name_to_model_path(model_name):\n",
    "\n",
    "    model_path = \"/datasets/huggingface_hub/models--\"+str(model_name)+\"/snapshots/\"\n",
    "\n",
    "    dirs = os.listdir(model_path)\n",
    "    if len(dirs) == 1:\n",
    "        return os.path.join(model_path, dirs[0])\n",
    "    else:\n",
    "        raise ValueError(f\"There is more than one file in the {model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a3f54-c13b-42eb-a59c-0ecd171436ec",
   "metadata": {},
   "source": [
    "## Download ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "26b08bee-b28a-4265-8911-d2ca934e78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_google = \"https://adstransparency.google.com/advertiser/AR13743371773506748417/creative/CR12193976855644078081?region=FR&platform=YOUTUBE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19332619-570b-4608-8c0c-32d86a8c4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"https://library.tiktok.com/ads/detail/?ad_id=1759642641055778\"\n",
    "test_video_1 = \"https://library.tiktok.com/api/v1/cdn/1739884858/video/aHR0cHM6Ly92NzcudGlrdG9rY2RuLmNvbS8wNGRlYmNiOWQ5NDA4N2Y2ZWI0MTc1NjY0ODIzMjBkNS82N2I0ZGRhNi92aWRlby90b3MvYWxpc2cvdG9zLWFsaXNnLXYtMDAwMC9vY3dRZGh3Q0JuSENOUWtVd29lNGc3b0ROQVFKR2VWYkRUQmtaZy8=/c1a21cbe-af88-4759-92a0-9294330bddea?a=475769&amp;bti=PDU2NmYwMy86&amp;ch=0&amp;cr=0&amp;dr=1&amp;cd=0%7C0%7C0%7C0&amp;cv=1&amp;br=268&amp;bt=134&amp;cs=0&amp;ds=1&amp;ft=.NpOcInz7ThYx.1OXq8Zmo&amp;mime_type=video_mp4&amp;qs=0&amp;rc=MzRmZjU5aTozaTdpNTU3aEBpM3J1Mzs6Zm8zajMzODYzNEAzYTU1Ll9gXmAxYF8uYzBfYSNeMTVgcjRfcTJgLS1kMC1zcw%3D%3D&amp;vvpl=1&amp;l=20250218132057B89936FF61D090DEBABE&amp;btag=e000b0000&amp;cc=13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fee72d61-6e94-4ef2-8b24-cf49b2b3401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_2 = \"https://library.tiktok.com/ads/detail/?ad_id=1821860479764594\"\n",
    "test_video_2 = \"https://library.tiktok.com/api/v1/cdn/1740063422/video/aHR0cHM6Ly92NzcudGlrdG9rY2RuLmNvbS9kYmJlYzE3NjI4ZGY5MDU1NWI4N2NiMmE4ZmU1NmFmYy82N2I3OTc0Yi92aWRlby90b3MvYWxpc2cvdG9zLWFsaXNnLXZlLTAwNTFjMDAxLXNnL29ZQXdER2NQZ0laQVViZVJHNGZlQ0xFSG9HVzh3eGc3cVhsaktBLw==/47fee5b8-1dc5-47fd-ac17-bc88eca76964?a=475769&amp;bti=PDU2NmYwMy86&amp;ch=0&amp;cr=0&amp;dr=1&amp;cd=0%7C0%7C0%7C0&amp;cv=1&amp;br=1822&amp;bt=911&amp;cs=0&amp;ds=1&amp;ft=.NpOcInz7Thkvr1OXq8Zmo&amp;mime_type=video_mp4&amp;qs=0&amp;rc=OGY0ZWdpaTM3ZmgzZTRlM0BpM3Q2M3g5cm1yeDMzODYzNEBjNmI1NmNfNS4xYC9iX2BeYSNrZmlyMmQ0ZTRgLS1kMC1zcw%3D%3D&amp;vvpl=1&amp;l=20250220145700A11D45138D8C960FCC5D&amp;btag=e00088000&amp;cc=13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "de7d2504-dbc1-43dd-8028-7278c58cccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_videos(list_videos):\n",
    "\n",
    "    for i in range(0,len(list_videos)):\n",
    "        url = list_videos[i]\n",
    "        h = httplib2.Http()\n",
    "        resp, content = h.request(url)\n",
    "        \n",
    "        if not os.path.exists(videos):\n",
    "            os.makedirs(videos)\n",
    "            \n",
    "        if resp.status == 200:\n",
    "            output_path = os.path.join(videos, f\"video_{i}.mp4\") \n",
    "            urllib.request.urlretrieve(url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "07ce1d67-c42e-4f1f-961d-25539e81c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_videos = [test_video_1, test_video_2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "dc4ce3c2-ebef-44c5-806a-3aa2607bf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_videos(list_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94725c4-141e-4454-b5b1-a4233a8101f8",
   "metadata": {},
   "source": [
    "## Get frames from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e7eb6ec-a498-43aa-b897-4f06e7de41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder):\n",
    "    \n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0] \n",
    "    print(video_name)\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not capture.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "        \n",
    "    frame_number = 0\n",
    "    frame_skip = 3\n",
    "\n",
    "    saved_frame_count = 0  \n",
    "\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    while True:\n",
    "        ret, frame = capture.read() \n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_number % frame_skip == 0:\n",
    "            frame_filename = os.path.join(output_folder, f\"{video_name}_frame_{saved_frame_count}.jpg\") \n",
    "            try:\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "                saved_frame_count += 1\n",
    "                #print(f\"Saved frame: {frame_filename}\") #added print statement.\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving frame: {e}\")\n",
    "            saved_frame_count += 1 \n",
    "\n",
    "        frame_number += 1 \n",
    "\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f35a98-3d1b-4064-b63c-bd791f4608db",
   "metadata": {},
   "source": [
    "# Create Categories to analyze the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa044a-99fc-4677-9619-2da17c1d99a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_frame(video_name, frame):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(frame)\n",
    "        if text.strip():  # Check if the extracted text is not empty\n",
    "            #print(text)\n",
    "            category = \"text or image and text\"\n",
    "        else:\n",
    "            category = \"image\"\n",
    "            #return \"image\"\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        print(\"Error: Tesseract not found. Install it.\")\n",
    "        return \"unknown\" \n",
    "    except Exception as e: \n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        category = \"error\"\n",
    "        return \"unknown\"\n",
    "\n",
    "    return category, text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f96b46-d0df-445f-8b1a-e9db35ebaa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos = \"./test_videos\"\n",
    "output_frames = \"./output_frames\"\n",
    "csv_file_path = 'text_videos.csv' \n",
    "\n",
    "with open(csv_file_path, \"a\", newline=\"\", encoding=\"utf-8\") as csv_file:  \n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow(['video_name', 'frame_number', 'category', 'text']) \n",
    "\n",
    "    for filename in os.listdir(test_videos):\n",
    "        if filename.endswith((\".mp4\")):\n",
    "            video_name_without_extension = os.path.splitext(filename)[0]\n",
    "            if not os.path.exists(output_frames):\n",
    "                os.makedirs(output_frames)\n",
    "            for frame_name in os.listdir(os.path.join(output_frames, video_name_without_extension)):\n",
    "                path = os.path.join(output_frames, video_name_without_extension,frame_name)\n",
    "                category, text = categorize_frame(filename, path) # Pass writer to function\n",
    "                writer.writerow([filename, frame_name, category, text])\n",
    "       \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ae51bab0-993f-4362-8314-c76eaf7fc681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    for video in os.listdir(os.path.join(test_videos)):\n",
    "        video_path = os.path.join(test_videos, video)\n",
    "        print(video_path)\n",
    "        output_path = os.path.join(output_frames, video.split(\".\")[0])\n",
    "        print(output_path)\n",
    "        extract_frames(video_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf8e66-03f2-4c1e-9d52-8269cf92a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9de2b208-89b0-4a36-b772-e8d5d32b9426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai--clip-vit-base-patch32\"\n",
    "model_name_lab = model_name_to_model_path(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f30ec558-da1d-49bb-820e-0ce4f78be0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name_lab)\n",
    "model = AutoModelForZeroShotImageClassification.from_pretrained(model_name_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "25d45819-e9cf-4ee1-9e8d-e8704bf3243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list(glob.glob('output_frames/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8a929-77b6-4e56-a065-2863f8769051",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = list(glob.glob('output_frames/test_video_1/*.jpg'))\n",
    "print(\"Images:\", len(image_names))\n",
    "encoded_image = model.encode([Image.open(filepath) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "# Now we run the clustering algorithm. This function compares images aganist \n",
    "# all other images and returns a list with the pairs that have the highest \n",
    "# cosine similarity score\n",
    "processed_images = util.paraphrase_mining_embeddings(encoded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee7925-d17d-4663-b923-565ef33b5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the OpenAI CLIP Model\n",
    "\n",
    "\n",
    "# Next we compute the embeddings\n",
    "# To encode an image, you can use the following code:\n",
    "# from PIL import Image\n",
    "# encoded_image = model.encode(Image.open(filepath))\n",
    "image_names = list(glob.glob('output_frames/test_video_1/*.jpg'))\n",
    "print(\"Images:\", len(image_names))\n",
    "encoded_image = model.encode([Image.open(filepath) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "# Now we run the clustering algorithm. This function compares images aganist \n",
    "# all other images and returns a list with the pairs that have the highest \n",
    "# cosine similarity score\n",
    "processed_images = util.paraphrase_mining_embeddings(encoded_image)\n",
    "NUM_SIMILAR_IMAGES = 10 \n",
    "\n",
    "# =================\n",
    "# DUPLICATES\n",
    "# =================\n",
    "print('Finding duplicate images...')\n",
    "# Filter list for duplicates. Results are triplets (score, image_id1, image_id2) and is scorted in decreasing order\n",
    "# A duplicate image will have a score of 1.00\n",
    "# It may be 0.9999 due to lossy image compression (.jpg)\n",
    "duplicates = [image for image in processed_images if image[0] >= 0.999]\n",
    "\n",
    "# Output the top X duplicate images\n",
    "for score, image_id1, image_id2 in duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])\n",
    "\n",
    "# =================\n",
    "# NEAR DUPLICATES\n",
    "# =================\n",
    "print('Finding near duplicate images...')\n",
    "# Use a threshold parameter to identify two images as similar. By setting the threshold lower, \n",
    "# you will get larger clusters which have less similar images in it. Threshold 0 - 1.00\n",
    "# A threshold of 1.00 means the two images are exactly the same. Since we are finding near \n",
    "# duplicate images, we can set it at 0.99 or any number 0 < X < 1.00.\n",
    "threshold = 0.99\n",
    "near_duplicates = [image for image in processed_images if image[0] < threshold]\n",
    "\n",
    "for score, image_id1, image_id2 in near_duplicates[0:NUM_SIMILAR_IMAGES]:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads_env",
   "language": "python",
   "name": "ads_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
